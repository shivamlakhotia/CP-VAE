{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        # parser = argparse.ArgumentParser()â€¨",
    "# add_args(parser)\n",
    "args = Namespace(data_name=\"yelp\", bsz=128, load_path=\"checkpoint/ours-yelp/20201211-184811-first_run/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9482\n",
      "data done.\n"
     ]
    }
   ],
   "source": [
    "from utils.exp_utils import create_exp_dir\n",
    "from utils.text_utils import MonoTextData\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "# from models.decomposed_vae import DecomposedVAE\n",
    "import numpy as np\n",
    "from file_io import *\n",
    "from vocab import Vocabulary, build_vocab\n",
    "from models.vae import TrainerVAE, VAE\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "conf = config.CONFIG[args.data_name] # Need to update !!\n",
    "data_pth = \"data/%s\" % args.data_name\n",
    "train_data_pth = os.path.join(data_pth, \"train_identical_sentiment_90_tense.csv\")\n",
    "train_class = MonoTextData(train_data_pth, glove=True)\n",
    "train_data, train_sentiments, train_tenses = train_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "vocab = train_class.vocab\n",
    "print('Vocabulary size: %d' % len(vocab))\n",
    "\n",
    "test_data_pth = os.path.join(data_pth, \"test_identical_sentiment_90_tense.csv\")\n",
    "test_class = MonoTextData(test_data_pth, vocab=vocab, glove=True)\n",
    "test_data, test_sentiments, test_tenses = test_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "print(\"data done.\")\n",
    "\n",
    "params = conf[\"params\"]\n",
    "params[\"vae_params\"][\"vocab\"] = vocab\n",
    "params[\"vae_params\"][\"device\"] = device\n",
    "\n",
    "def add_args(parser):\n",
    "    parser.add_argument('--data_name', type=str, default='yelp',\n",
    "                        help='data name')\n",
    "    parser.add_argument('--train', type=str, default='./data/yelp/sentiment.train',\n",
    "                        help='train data path')\n",
    "    parser.add_argument('--dev', type=str, default='./data/yelp/sentiment.dev',\n",
    "                        help='val data path')\n",
    "    parser.add_argument('--test', type=str, default='./data/yelp/sentiment.test',\n",
    "                        help='test data path')\n",
    "    parser.add_argument('--load_path', type=str, default='',\n",
    "                        help='directory name to load')\n",
    "    parser.add_argument('--bsz', type=int, default=128,\n",
    "                        help='batch size for training')\n",
    "    parser.add_argument('--vocab', type=str, default='./tmp/yelp.vocab')\n",
    "    parser.add_argument('--embedding', type=str, default='./data/glove.840B.300d.txt')\n",
    "    parser.add_argument('--dim_emb', type=int, default=300)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     add_args(parser)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "from models.base_network import LSTMEncoder, StyleClassifier, ContentDecoder, SgivenC, LSTMDecoder\n",
    "\n",
    "class EvaluateVAE:\n",
    "    def __init__(self, test, test_labels1, test_labels2, load_path, vocab, vae_params):\n",
    "        super(EvaluateVAE, self).__init__()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "#         self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.load_path = load_path\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.test_data = test\n",
    "        self.test_labels1 = test_labels1\n",
    "        self.test_labels2 = test_labels2\n",
    "\n",
    "        self.vae = VAE(**vae_params)\n",
    "        if self.use_cuda:\n",
    "            self.vae.cuda()\n",
    "\n",
    "        self.nbatch = len(self.test_data)\n",
    "        self.batch_size = len(self.test_data[0])\n",
    "        self.load(self.load_path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        self.vae.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def eval_style_transfer(self):\n",
    "        sent_idx = 0\n",
    "        total_sent = 0\n",
    "        df_111 = []\n",
    "        df_222 = []\n",
    "        df_221 = []\n",
    "        df_112 = []\n",
    "        df_121 = []\n",
    "        df_212 = []\n",
    "        \n",
    "        for i in range(800,820):\n",
    "            for next_sent_idx in range(sent_idx+1, self.test_labels1[i].size()[0]):\n",
    "                if total_sent >= 10:\n",
    "                    break\n",
    "                if (self.test_labels1[i][sent_idx:sent_idx+1][0] != self.test_labels1[i][next_sent_idx:next_sent_idx+1][0]) and (self.test_labels2[i][sent_idx:sent_idx+1][0] != self.test_labels2[i][next_sent_idx:next_sent_idx+1][0]):\n",
    "                    print(\"Sizes:\", self.test_data[i].size(), self.test_labels1[i].size(), self.test_labels2[i].size())\n",
    "                    print(\"Sizes_Sliced:\", self.test_data[i][:, sent_idx:sent_idx+1].size(), self.test_data[i][:, next_sent_idx:next_sent_idx+1].size())\n",
    "\n",
    "                    original_sentence_11 = \"\"\n",
    "                    original_sentence_22 = \"\"\n",
    "\n",
    "                    for j in range(self.test_data[i].size()[0]):\n",
    "                        original_sentence_11 += self.vocab.id2word(self.test_data[i][j, sent_idx:sent_idx+1]) + \" \"\n",
    "                        original_sentence_22 += self.vocab.id2word(self.test_data[i][j, next_sent_idx:next_sent_idx+1]) + \" \"\n",
    "\n",
    "                    print(\"11 original_sentence:\", original_sentence_11, \"tense:\", self.test_labels1[i][sent_idx:sent_idx+1], \"sentiment:\", self.test_labels2[i][sent_idx:sent_idx+1])\n",
    "                    print(\"22 original_sentence:\", original_sentence_22, \"tense:\", self.test_labels1[i][next_sent_idx:next_sent_idx+1], \"sentiment:\", self.test_labels2[i][next_sent_idx:next_sent_idx+1])\n",
    "                    c1, s1_1, s1_2, _ = self.vae.encode(self.test_data[i][:, sent_idx:sent_idx+1])\n",
    "                    c2, s2_1, s2_2, _ = self.vae.encode(self.test_data[i][:, next_sent_idx:next_sent_idx+1])\n",
    "\n",
    "                    transfer_sentence_112 = (self.vae.decoder.beam_search_decode(c1, s1_1, s2_2)).cpu()\n",
    "                    transfer_sentence_221 = (self.vae.decoder.beam_search_decode(c2, s2_1, s1_2)).cpu()\n",
    "                    transfer_sentence_111 = (self.vae.decoder.beam_search_decode(c1, s1_1, s1_2)).cpu()\n",
    "                    transfer_sentence_222 = (self.vae.decoder.beam_search_decode(c2, s2_1, s2_2)).cpu()\n",
    "                    transfer_sentence_121 = (self.vae.decoder.beam_search_decode(c1, s2_1, s1_2)).cpu()\n",
    "                    transfer_sentence_212 = (self.vae.decoder.beam_search_decode(c2, s1_1, s2_2)).cpu()\n",
    "\n",
    "                    df_111 += [\" \".join(transfer_sentence_111[0][:-1])]\n",
    "                    df_222 += [\" \".join(transfer_sentence_222[0][:-1])]\n",
    "                    df_112 += [\" \".join(transfer_sentence_112[0][:-1])]\n",
    "                    df_221 += [\" \".join(transfer_sentence_221[0][:-1])]\n",
    "                    df_121 += [\" \".join(transfer_sentence_121[0][:-1])]\n",
    "                    df_212 += [\" \".join(transfer_sentence_212[0][:-1])]\n",
    "                    \n",
    "#                     print(\"111 sentence:\", \" \".join(transfer_sentence_111[0][:-1]))\n",
    "#                     print(\"222 sentence:\", \" \".join(transfer_sentence_222[0][:-1]))\n",
    "#                     print(\"112 sentence:\", \" \".join(transfer_sentence_112[0][:-1]))\n",
    "#                     print(\"221 sentence:\", \" \".join(transfer_sentence_221[0][:-1]))\n",
    "#                     print(\"121 sentence:\", \" \".join(transfer_sentence_121[0][:-1]))\n",
    "#                     print(\"212 sentence:\", \" \".join(transfer_sentence_212[0][:-1]))\n",
    "                    total_sent += 1\n",
    "                    break\n",
    "        \n",
    "        pd.options.display.max_colwidth = 100\n",
    "        df = pd.DataFrame()\n",
    "        df[\"OriginalA\"] = df_111\n",
    "        df[\"OriginalB\"] = df_222\n",
    "        df[\"A - Sent Swapped\"] = df_121\n",
    "        df[\"A - Tense Swapped\"] = df_112\n",
    "        df[\"B - Sent Swapped\"] = df_212\n",
    "        df[\"B - Tense Swapped\"] = df_221\n",
    "        print(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: torch.Size([12, 128]) torch.Size([128]) torch.Size([128])\n",
      "Sizes_Sliced: torch.Size([12, 1]) torch.Size([12, 1])\n",
      "11 original_sentence: <s> and there is no even a place to sit . </s>  tense: tensor([0]) sentiment: tensor([1])\n",
      "22 original_sentence: <s> these guys absolutely knocked themselves out for our event ! </s>  tense: tensor([1]) sentiment: tensor([0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-522f7a5785ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevalVAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluateVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tenses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vae_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_style_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-62d195a675c5>\u001b[0m in \u001b[0;36meval_style_transfer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"11 original_sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_sentence_11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tense:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msent_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentiment:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msent_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"22 original_sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_sentence_22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tense:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_sent_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnext_sent_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentiment:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_sent_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnext_sent_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msent_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_sent_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnext_sent_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/shivam/idm/Disentangle_Extend/models/vae.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, nsamples)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/shivam/idm/Disentangle_Extend/models/base_network.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, inputs, nsamples)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmu_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_s2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/shivam/idm/Disentangle_Extend/models/base_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m#     word_embed = self.embed(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mword_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cp-vae-idm/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cp-vae-idm/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/anaconda3/envs/cp-vae-idm/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "evalVAE = EvaluateVAE(train_data, train_sentiments, train_tenses, args.load_path, vocab, params[\"vae_params\"])\n",
    "df = evalVAE.eval_style_transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
