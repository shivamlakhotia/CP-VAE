{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[“CUDA_DEVICE_ORDER”]=“PCI_BUS_ID”\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.exp_utils import create_exp_dir\n",
    "from utils.text_utils import MonoTextData\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "# from models.decomposed_vae import DecomposedVAE\n",
    "import numpy as np\n",
    "# from vocab import Vocabulary, build_vocab\n",
    "from models.vae import VAE\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "class AmolData:\n",
    "    def __init__(self, test, test_labels1, test_labels2, load_path, vocab, vae_params):\n",
    "        super(AmolData, self).__init__()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.load_path = load_path\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.test_data = test\n",
    "        self.test_labels1 = test_labels1\n",
    "        self.test_labels2 = test_labels2\n",
    "\n",
    "        self.vae = VAE(**vae_params)\n",
    "        if self.use_cuda:\n",
    "            self.vae.to(self.device)\n",
    "\n",
    "        self.nbatch = len(self.test_data)\n",
    "        self.load(self.load_path)\n",
    "        self.load_embeddings()\n",
    "    \n",
    "    def load(self, path):\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        self.vae.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def load_embeddings(self):\n",
    "        data = np.load('data/demo_embeddings.npz')\n",
    "\n",
    "        self.mu_pos = torch.tensor(data['mu_pos']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_pos = torch.tensor(data['logvar_pos']).unsqueeze(0).to(self.device)\n",
    "        self.mu_neg = torch.tensor(data['mu_neg']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_neg = torch.tensor(data['logvar_neg']).unsqueeze(0).to(self.device)\n",
    "        self.mu_past = torch.tensor(data['mu_past']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_past = torch.tensor(data['logvar_past']).unsqueeze(0).to(self.device)\n",
    "        self.mu_present = torch.tensor(data['mu_present']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_present = torch.tensor(data['logvar_present']).unsqueeze(0).to(self.device)\n",
    "\n",
    "    \n",
    "    def run_conversion(self, utterance, sentiment=0, tense=0):\n",
    "#         print(utterance, sentiment, tense)\n",
    "        self.vae.eval()\n",
    "        mu_c, logvar_c, _, logvar_s1, _, logvar_s2 = self.vae.encoder(utterance)\n",
    "        if (sentiment == 0):\n",
    "            mu_s1 = self.mu_neg\n",
    "        else:\n",
    "            mu_s1 = self.mu_pos\n",
    "        if (tense == 0):\n",
    "            mu_s2 = self.mu_past\n",
    "        else:\n",
    "            mu_s2 = self.mu_present\n",
    "        return self.vae.decoder.beam_search_decode(mu_c.unsqueeze(0), mu_s1, mu_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # np.random.seed(0)\n",
    "    # torch.manual_seed(0)\n",
    "\n",
    "    conf = config.CONFIG[args.data_name] # Need to update !!\n",
    "    data_pth = \"data/%s\" % args.data_name\n",
    "    print(data_pth)\n",
    "    train_data_pth = os.path.join(data_pth, \"train_identical_sentiment_90_tense.csv\")\n",
    "    train_class = MonoTextData(train_data_pth, glove=True)\n",
    "    train_data, train_sentiments, train_tenses = train_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "    vocab = train_class.vocab\n",
    "    print('Vocabulary size: %d' % len(vocab))\n",
    "\n",
    "    test_data_pth = os.path.join(data_pth, \"eval_data.csv\")\n",
    "    test_class = MonoTextData(test_data_pth, vocab=vocab, glove=True)\n",
    "    test_data, test_sentiments, test_tenses = test_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "    print(\"data done.\")\n",
    "\n",
    "    params = conf[\"params\"]\n",
    "    params[\"vae_params\"][\"vocab\"] = vocab\n",
    "    params[\"vae_params\"][\"device\"] = device\n",
    "\n",
    "    amolData = AmolData(test_data, test_sentiments, test_tenses, args.load_path, vocab, params[\"vae_params\"])\n",
    "    return amolData, train_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(data_name=\"yelp\", load_path = './checkpoint/ours-yelp/20201211-184811-first_run/', vocab = './tmp/yelp.vocab', bsz=256, embedding = './data/glove.840B.300d.txt', dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/yelp\n",
      "Vocabulary size: 9482\n",
      "data done.\n"
     ]
    }
   ],
   "source": [
    "obj, mtd = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sentence = input()\n",
    "input_sentence = \"The service is bad\"\n",
    "processed_input = [mtd.vocab[w] for w in input_sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_input = mtd._to_tensor([processed_input], False, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1],\n",
      "        [  3],\n",
      "        [ 21],\n",
      "        [  9],\n",
      "        [114],\n",
      "        [  2]], device='cuda:0') 1 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<s>', '5-star', 'service', 'is', 'good', '.', '</s>']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.run_conversion(processed_input[0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: \n",
      "the service is good\n",
      "Choose Sentiment:\n",
      "Negative:0\n",
      "Positive:1\n",
      "0\n",
      "Choose Tense:\n",
      "Past:0\n",
      "Present:1\n",
      "1\n",
      "tensor([[ 1],\n",
      "        [ 5],\n",
      "        [21],\n",
      "        [ 9],\n",
      "        [19],\n",
      "        [ 2]], device='cuda:0') 0 1\n",
      "<s> the service is horrible . </s>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-bb11d67c0c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Sentence: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Choose Sentiment:\\nNegative:0\\nPositive:1\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Choose Tense:\\nPast:0\\nPresent:1\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# input_sentence = \"The service is bad\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cp-vae/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cp-vae/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    input_sentence = input(\"Input Sentence: \\n\")\n",
    "    sentiment = input(\"Choose Sentiment:\\nNegative:0\\nPositive:1\\n\")\n",
    "    tense = input(\"Choose Tense:\\nPast:0\\nPresent:1\\n\")\n",
    "    # input_sentence = \"The service is bad\"\n",
    "    # sentiment=0\n",
    "    # tense = 0\n",
    "    processed_input = [mtd.vocab[w] for w in input_sentence.split()]\n",
    "    processed_input = mtd._to_tensor([processed_input], False, 'cuda')\n",
    "    output = obj.run_conversion(processed_input[0], int(sentiment), int(tense))\n",
    "    output = \" \".join(output[0])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
