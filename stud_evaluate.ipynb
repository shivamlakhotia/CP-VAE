{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        # parser = argparse.ArgumentParser()â€¨",
    "# add_args(parser)\n",
    "args = Namespace(data_name=\"yelp\", bsz=128, load_path=\"checkpoint/ours-yelp/20201211-184811-first_run/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.exp_utils import create_exp_dir\n",
    "from utils.text_utils import MonoTextData\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "# from models.decomposed_vae import DecomposedVAE\n",
    "import numpy as np\n",
    "from file_io import *\n",
    "from vocab import Vocabulary, build_vocab\n",
    "from models.vae import TrainerVAE, VAE\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "conf = config.CONFIG[args.data_name] # Need to update !!\n",
    "data_pth = \"data/%s\" % args.data_name\n",
    "train_data_pth = os.path.join(data_pth, \"train_identical_sentiment_90_tense.csv\")\n",
    "train_class = MonoTextData(train_data_pth, glove=True)\n",
    "train_data, train_sentiments, train_tenses = train_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "vocab = train_class.vocab\n",
    "print('Vocabulary size: %d' % len(vocab))\n",
    "\n",
    "test_data_pth = os.path.join(data_pth, \"test_identical_sentiment_90_tense.csv\")\n",
    "test_class = MonoTextData(test_data_pth, vocab=vocab, glove=True)\n",
    "test_data, test_sentiments, test_tenses = test_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "print(\"data done.\")\n",
    "\n",
    "params = conf[\"params\"]\n",
    "params[\"vae_params\"][\"vocab\"] = vocab\n",
    "params[\"vae_params\"][\"device\"] = device\n",
    "\n",
    "def add_args(parser):\n",
    "    parser.add_argument('--data_name', type=str, default='yelp',\n",
    "                        help='data name')\n",
    "    parser.add_argument('--train', type=str, default='./data/yelp/sentiment.train',\n",
    "                        help='train data path')\n",
    "    parser.add_argument('--dev', type=str, default='./data/yelp/sentiment.dev',\n",
    "                        help='val data path')\n",
    "    parser.add_argument('--test', type=str, default='./data/yelp/sentiment.test',\n",
    "                        help='test data path')\n",
    "    parser.add_argument('--load_path', type=str, default='',\n",
    "                        help='directory name to load')\n",
    "    parser.add_argument('--bsz', type=int, default=128,\n",
    "                        help='batch size for training')\n",
    "    parser.add_argument('--vocab', type=str, default='./tmp/yelp.vocab')\n",
    "    parser.add_argument('--embedding', type=str, default='./data/glove.840B.300d.txt')\n",
    "    parser.add_argument('--dim_emb', type=int, default=300)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     add_args(parser)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "from models.base_network import LSTMEncoder, StyleClassifier, ContentDecoder, SgivenC, LSTMDecoder\n",
    "\n",
    "class EvaluateVAE:\n",
    "    def __init__(self, test, test_labels1, test_labels2, load_path, vocab, vae_params):\n",
    "        super(EvaluateVAE, self).__init__()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "#         self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.load_path = load_path\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.test_data = test\n",
    "        self.test_labels1 = test_labels1\n",
    "        self.test_labels2 = test_labels2\n",
    "\n",
    "        self.vae = VAE(**vae_params)\n",
    "        if self.use_cuda:\n",
    "            self.vae.cuda()\n",
    "\n",
    "        self.nbatch = len(self.test_data)\n",
    "        self.batch_size = len(self.test_data[0])\n",
    "        self.load(self.load_path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        self.vae.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def eval_style_transfer(self):\n",
    "        sent_idx = 0\n",
    "        total_sent = 0\n",
    "        df_111 = []\n",
    "        df_222 = []\n",
    "        df_221 = []\n",
    "        df_112 = []\n",
    "        df_121 = []\n",
    "        df_212 = []\n",
    "        \n",
    "        for i in range(800,820):\n",
    "            for next_sent_idx in range(sent_idx+1, self.test_labels1[i].size()[0]):\n",
    "                if total_sent >= 10:\n",
    "                    break\n",
    "                if (self.test_labels1[i][sent_idx:sent_idx+1][0] != self.test_labels1[i][next_sent_idx:next_sent_idx+1][0]) and (self.test_labels2[i][sent_idx:sent_idx+1][0] != self.test_labels2[i][next_sent_idx:next_sent_idx+1][0]):\n",
    "                    print(\"Sizes:\", self.test_data[i].size(), self.test_labels1[i].size(), self.test_labels2[i].size())\n",
    "                    print(\"Sizes_Sliced:\", self.test_data[i][:, sent_idx:sent_idx+1].size(), self.test_data[i][:, next_sent_idx:next_sent_idx+1].size())\n",
    "\n",
    "                    original_sentence_11 = \"\"\n",
    "                    original_sentence_22 = \"\"\n",
    "\n",
    "                    for j in range(self.test_data[i].size()[0]):\n",
    "                        original_sentence_11 += self.vocab.id2word(self.test_data[i][j, sent_idx:sent_idx+1]) + \" \"\n",
    "                        original_sentence_22 += self.vocab.id2word(self.test_data[i][j, next_sent_idx:next_sent_idx+1]) + \" \"\n",
    "\n",
    "                    print(\"11 original_sentence:\", original_sentence_11, \"tense:\", self.test_labels1[i][sent_idx:sent_idx+1], \"sentiment:\", self.test_labels2[i][sent_idx:sent_idx+1])\n",
    "                    print(\"22 original_sentence:\", original_sentence_22, \"tense:\", self.test_labels1[i][next_sent_idx:next_sent_idx+1], \"sentiment:\", self.test_labels2[i][next_sent_idx:next_sent_idx+1])\n",
    "                    c1, s1_1, s1_2, _ = self.vae.encode(self.test_data[i][:, sent_idx:sent_idx+1])\n",
    "                    c2, s2_1, s2_2, _ = self.vae.encode(self.test_data[i][:, next_sent_idx:next_sent_idx+1])\n",
    "\n",
    "                    transfer_sentence_112 = (self.vae.decoder.beam_search_decode(c1, s1_1, s2_2)).cpu()\n",
    "                    transfer_sentence_221 = (self.vae.decoder.beam_search_decode(c2, s2_1, s1_2)).cpu()\n",
    "                    transfer_sentence_111 = (self.vae.decoder.beam_search_decode(c1, s1_1, s1_2)).cpu()\n",
    "                    transfer_sentence_222 = (self.vae.decoder.beam_search_decode(c2, s2_1, s2_2)).cpu()\n",
    "                    transfer_sentence_121 = (self.vae.decoder.beam_search_decode(c1, s2_1, s1_2)).cpu()\n",
    "                    transfer_sentence_212 = (self.vae.decoder.beam_search_decode(c2, s1_1, s2_2)).cpu()\n",
    "\n",
    "                    df_111 += [\" \".join(transfer_sentence_111[0][:-1])]\n",
    "                    df_222 += [\" \".join(transfer_sentence_222[0][:-1])]\n",
    "                    df_112 += [\" \".join(transfer_sentence_112[0][:-1])]\n",
    "                    df_221 += [\" \".join(transfer_sentence_221[0][:-1])]\n",
    "                    df_121 += [\" \".join(transfer_sentence_121[0][:-1])]\n",
    "                    df_212 += [\" \".join(transfer_sentence_212[0][:-1])]\n",
    "                    \n",
    "#                     print(\"111 sentence:\", \" \".join(transfer_sentence_111[0][:-1]))\n",
    "#                     print(\"222 sentence:\", \" \".join(transfer_sentence_222[0][:-1]))\n",
    "#                     print(\"112 sentence:\", \" \".join(transfer_sentence_112[0][:-1]))\n",
    "#                     print(\"221 sentence:\", \" \".join(transfer_sentence_221[0][:-1]))\n",
    "#                     print(\"121 sentence:\", \" \".join(transfer_sentence_121[0][:-1]))\n",
    "#                     print(\"212 sentence:\", \" \".join(transfer_sentence_212[0][:-1]))\n",
    "                    total_sent += 1\n",
    "                    break\n",
    "        \n",
    "        pd.options.display.max_colwidth = 100\n",
    "        df = pd.DataFrame()\n",
    "        df[\"OriginalA\"] = df_111\n",
    "        df[\"OriginalB\"] = df_222\n",
    "        df[\"A - Sent Swapped\"] = df_121\n",
    "        df[\"A - Tense Swapped\"] = df_112\n",
    "        df[\"B - Sent Swapped\"] = df_212\n",
    "        df[\"B - Tense Swapped\"] = df_221\n",
    "        print(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalVAE = EvaluateVAE(train_data, train_sentiments, train_tenses, args.load_path, vocab, params[\"vae_params\"])\n",
    "df = evalVAE.eval_style_transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
