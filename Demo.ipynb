{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.exp_utils import create_exp_dir\n",
    "from utils.text_utils import MonoTextData\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "# from models.decomposed_vae import DecomposedVAE\n",
    "import numpy as np\n",
    "# from vocab import Vocabulary, build_vocab\n",
    "from models.vae import VAE\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "class AmolData:\n",
    "    def __init__(self, test, test_labels1, test_labels2, load_path, vocab, vae_params):\n",
    "        super(AmolData, self).__init__()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.load_path = load_path\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.test_data = test\n",
    "        self.test_labels1 = test_labels1\n",
    "        self.test_labels2 = test_labels2\n",
    "\n",
    "        self.vae = VAE(**vae_params)\n",
    "        if self.use_cuda:\n",
    "            self.vae.cuda()\n",
    "\n",
    "        self.nbatch = len(self.test_data)\n",
    "        self.load(self.load_path)\n",
    "        self.load_embeddings()\n",
    "    \n",
    "    def load(self, path):\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        self.vae.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def load_embeddings(self):\n",
    "        data = np.load('data/demo_embeddings.npz')\n",
    "\n",
    "        self.mu_pos = torch.tensor(data['mu_pos']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_pos = torch.tensor(data['logvar_pos']).unsqueeze(0).to(self.device)\n",
    "        self.mu_neg = torch.tensor(data['mu_neg']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_neg = torch.tensor(data['logvar_neg']).unsqueeze(0).to(self.device)\n",
    "        self.mu_past = torch.tensor(data['mu_past']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_past = torch.tensor(data['logvar_past']).unsqueeze(0).to(self.device)\n",
    "        self.mu_present = torch.tensor(data['mu_present']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_present = torch.tensor(data['logvar_present']).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def create_data(self):\n",
    "        self.vae.eval()\n",
    "        total_sent = 0\n",
    "        df_original = []\n",
    "        df_sentiment_swapped = []\n",
    "        df_sentiment_swapped_l1 = []\n",
    "        df_sentiment_swapped_l2 = []\n",
    "\n",
    "        df_tense_swapped = []\n",
    "        df_tense_swapped_l1 = []\n",
    "        df_tense_swapped_l2 = []\n",
    "        df_both_swapped = []\n",
    "        df_both_swapped_l1 = []\n",
    "        df_both_swapped_l2 = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            while total_sent < 100:\n",
    "                total_sent += 1\n",
    "                batch_idx = random.randint(0, self.nbatch-1)\n",
    "                sent_idx = random.randint(0, self.test_data[batch_idx].size()[1]-1)\n",
    "                mu_c, logvar_c, mu_s1, logvar_s1, mu_s2, logvar_s2 = self.vae.encoder(self.test_data[batch_idx][:, sent_idx:sent_idx+1])\n",
    "                original_sentence = \"\"\n",
    "\n",
    "                for j in range(self.test_data[batch_idx].size()[0]):\n",
    "                    original_sentence += self.vocab.id2word(self.test_data[batch_idx][j, sent_idx:sent_idx+1]) + \" \"\n",
    "                \n",
    "                original_sentiment = self.test_labels1[batch_idx][sent_idx]\n",
    "                original_tense = self.test_labels2[batch_idx][sent_idx]\n",
    "                print(\"original_sentence:\", original_sentence, \"sentiment:\", original_sentiment, \"tense:\", original_tense)\n",
    "\n",
    "                c, s1, s2, _ = self.vae.encode(self.test_data[batch_idx][:, sent_idx:sent_idx+1])\n",
    "\n",
    "                if original_sentiment == 0:\n",
    "                    transfer_sentiment = self.vae.decoder.beam_search_decode(c, self.mu_pos, s2)\n",
    "                    sentiment_swap_l1 = 1\n",
    "                    sentiment_swap_l2 = original_tense.item()\n",
    "                elif original_sentiment == 1:\n",
    "                    transfer_sentiment = self.vae.decoder.beam_search_decode(c, self.mu_neg, s2)\n",
    "                    sentiment_swap_l1 = 0\n",
    "                    sentiment_swap_l2 = original_tense.item()\n",
    "\n",
    "                if original_tense == 0:\n",
    "                    transfer_tense = self.vae.decoder.beam_search_decode(c, s1, self.mu_present)\n",
    "                    tense_swap_l1 = original_sentiment.item()\n",
    "                    tense_swap_l2 = 1\n",
    "                elif original_tense == 1:\n",
    "                    transfer_tense = self.vae.decoder.beam_search_decode(c, s1, self.mu_past)\n",
    "                    tense_swap_l1 = original_sentiment.item()\n",
    "                    tense_swap_l2 = 0\n",
    "                \n",
    "                if original_sentiment == 0 and original_tense == 0:\n",
    "                    transfer_both = self.vae.decoder.beam_search_decode(c, self.mu_pos, self.mu_present)\n",
    "                    both_swap_l1 = 1\n",
    "                    both_swap_l2 = 1\n",
    "                elif original_sentiment == 0 and original_tense == 1:\n",
    "                    transfer_both = self.vae.decoder.beam_search_decode(c, self.mu_pos, self.mu_past)\n",
    "                    both_swap_l1 = 1\n",
    "                    both_swap_l2 = 0\n",
    "                elif original_sentiment == 1 and original_tense == 0:\n",
    "                    transfer_both = self.vae.decoder.beam_search_decode(c, self.mu_neg, self.mu_present)\n",
    "                    both_swap_l1 = 0\n",
    "                    both_swap_l2 = 1\n",
    "                elif original_sentiment == 1 and original_tense == 1:\n",
    "                    transfer_both = self.vae.decoder.beam_search_decode(c, self.mu_neg, self.mu_past)\n",
    "                    both_swap_l1 = 0\n",
    "                    both_swap_l2 = 0\n",
    "\n",
    "                df_original.append(original_sentence)\n",
    "                df_sentiment_swapped.append(\" \".join(transfer_sentiment[0][:-1]))\n",
    "                df_tense_swapped.append(\" \".join(transfer_tense[0][:-1]))\n",
    "                df_both_swapped.append(\" \".join(transfer_both[0][:-1]))\n",
    "                df_sentiment_swapped_l1.append(sentiment_swap_l1)\n",
    "                df_sentiment_swapped_l2.append(sentiment_swap_l2)\n",
    "                df_tense_swapped_l1.append(tense_swap_l1)\n",
    "                df_tense_swapped_l2.append(tense_swap_l2)\n",
    "                df_both_swapped_l1.append(both_swap_l1)\n",
    "                df_both_swapped_l2.append(both_swap_l2)\n",
    "            \n",
    "        pd.options.display.max_colwidth = 100\n",
    "        df_sentiment_swap_file = pd.DataFrame()\n",
    "        df_sentiment_swap_file[\"Original\"] = df_original\n",
    "        df_sentiment_swap_file[\"Swapped\"] = df_sentiment_swapped\n",
    "        df_sentiment_swap_file[\"New Sentiment Label\"] = df_sentiment_swapped_l1\n",
    "        df_sentiment_swap_file[\"New Tense Label\"] = df_sentiment_swapped_l2\n",
    "        df_sentiment_swap_file.to_csv('data/amol_sentiment_swapped_file.csv', sep='\\t')\n",
    "\n",
    "        df_tense_swap_file = pd.DataFrame()\n",
    "        df_tense_swap_file[\"Original\"] = df_original\n",
    "        df_tense_swap_file[\"Swapped\"] = df_tense_swapped\n",
    "        df_tense_swap_file[\"New Sentiment Label\"] = df_tense_swapped_l1\n",
    "        df_tense_swap_file[\"New Tense Label\"] = df_tense_swapped_l2\n",
    "        df_tense_swap_file.to_csv('data/amol_tense_swapped_file.csv', sep='\\t')\n",
    "\n",
    "        df_both_swap_file = pd.DataFrame()\n",
    "        df_both_swap_file[\"Original\"] = df_original\n",
    "        df_both_swap_file[\"Swapped\"] = df_both_swapped\n",
    "        df_both_swap_file[\"New Sentiment Label\"] = df_both_swapped_l1\n",
    "        df_both_swap_file[\"New Tense Label\"] = df_both_swapped_l2\n",
    "        df_both_swap_file.to_csv('data/amol_both_swapped_file.csv', sep='\\t')\n",
    "\n",
    "        # print(df)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # np.random.seed(0)\n",
    "    # torch.manual_seed(0)\n",
    "\n",
    "    conf = config.CONFIG[args.data_name] # Need to update !!\n",
    "    data_pth = \"data/%s\" % args.data_name\n",
    "    print(data_pth)\n",
    "    train_data_pth = os.path.join(data_pth, \"train_identical_sentiment_90_tense.csv\")\n",
    "    train_class = MonoTextData(train_data_pth, glove=True)\n",
    "    train_data, train_sentiments, train_tenses = train_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "    vocab = train_class.vocab\n",
    "    print('Vocabulary size: %d' % len(vocab))\n",
    "\n",
    "    test_data_pth = os.path.join(data_pth, \"eval_data.csv\")\n",
    "    test_class = MonoTextData(test_data_pth, vocab=vocab, glove=True)\n",
    "    test_data, test_sentiments, test_tenses = test_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "    print(\"data done.\")\n",
    "\n",
    "    params = conf[\"params\"]\n",
    "    params[\"vae_params\"][\"vocab\"] = vocab\n",
    "    params[\"vae_params\"][\"device\"] = device\n",
    "\n",
    "    amolData = AmolData(test_data, test_sentiments, test_tenses, args.load_path, vocab, params[\"vae_params\"])\n",
    "    amolData.create_data()\n",
    "\n",
    "def add_args(parser):\n",
    "    parser.add_argument('--data_name', type=str, default='yelp',\n",
    "                        help='data name')\n",
    "    parser.add_argument('--load_path', type=str, default='',\n",
    "                        help='directory name to load')\n",
    "    parser.add_argument('--bsz', type=int, default=128,\n",
    "                        help='batch size for training')\n",
    "    parser.add_argument('--vocab', type=str, default='./tmp/yelp.vocab')\n",
    "    parser.add_argument('--embedding', type=str, default='./data/glove.840B.300d.txt')\n",
    "    parser.add_argument('--dim_emb', type=int, default=300)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     add_args(parser)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(data_name=\"yelp\", load_path = './checkpoint/working-model', vocab = './tmp/yelp.vocab', bsz=1, embedding = './data/glove.840B.300d.txt', dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/yelp\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3f47c9a9b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-7ac688330a50>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mtrain_data_pth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_identical_sentiment_90_tense.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtrain_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonoTextData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_pth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_data_batch_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/shivam/CP-VAE/utils/text_utils.py\u001b[0m in \u001b[0;36mcreate_data_batch_labels\u001b[0;34m(self, batch_size, device, batch_first, min_len)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mbatch_sentiment_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                     \u001b[0mbatch_tense_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtense_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
