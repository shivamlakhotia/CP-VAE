{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.bleu import compute_bleu\n",
    "# os.environ[“CUDA_DEVICE_ORDER”]=“PCI_BUS_ID”\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.exp_utils import create_exp_dir\n",
    "from utils.text_utils import MonoTextData\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "# from models.decomposed_vae import DecomposedVAE\n",
    "import numpy as np\n",
    "# from vocab import Vocabulary, build_vocab\n",
    "from models.vae import VAE\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "class AmolData:\n",
    "    def __init__(self, test, test_labels1, test_labels2, load_path, vocab, vae_params):\n",
    "        super(AmolData, self).__init__()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.load_path = load_path\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.test_data = test\n",
    "        self.test_labels1 = test_labels1\n",
    "        self.test_labels2 = test_labels2\n",
    "\n",
    "        self.vae = VAE(**vae_params)\n",
    "        if self.use_cuda:\n",
    "            self.vae.to(self.device)\n",
    "\n",
    "        self.nbatch = len(self.test_data)\n",
    "        self.load(self.load_path)\n",
    "        self.load_embeddings()\n",
    "    \n",
    "    def load(self, path):\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        self.vae.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def load_embeddings(self):\n",
    "        data = np.load('data/demo_embeddings.npz')\n",
    "\n",
    "        self.mu_pos = torch.tensor(data['mu_pos']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_pos = torch.tensor(data['logvar_pos']).unsqueeze(0).to(self.device)\n",
    "        self.mu_neg = torch.tensor(data['mu_neg']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_neg = torch.tensor(data['logvar_neg']).unsqueeze(0).to(self.device)\n",
    "        self.mu_past = torch.tensor(data['mu_past']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_past = torch.tensor(data['logvar_past']).unsqueeze(0).to(self.device)\n",
    "        self.mu_present = torch.tensor(data['mu_present']).unsqueeze(0).to(self.device)\n",
    "        self.logvar_present = torch.tensor(data['logvar_present']).unsqueeze(0).to(self.device)\n",
    "\n",
    "    \n",
    "    def run_conversion(self, utterance, sentiment=0, tense=0):\n",
    "#         print(utterance, sentiment, tense)\n",
    "        self.vae.eval()\n",
    "        mu_c, logvar_c, _, logvar_s1, mu_s2, logvar_s2 = self.vae.encoder(utterance)\n",
    "        if (sentiment == 0):\n",
    "            mu_s1 = self.mu_neg\n",
    "        else:\n",
    "            mu_s1 = self.mu_pos\n",
    "        \n",
    "        return self.vae.decoder.beam_search_decode(mu_c.unsqueeze(0), mu_s1, mu_s2.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # np.random.seed(0)\n",
    "    # torch.manual_seed(0)\n",
    "\n",
    "    conf = config.CONFIG[args.data_name] # Need to update !!\n",
    "    data_pth = \"data/%s\" % args.data_name\n",
    "    print(data_pth)\n",
    "    train_data_pth = os.path.join(data_pth, \"train_identical_sentiment_90_tense.csv\")\n",
    "    train_class = MonoTextData(train_data_pth, glove=True)\n",
    "    train_data, train_sentiments, train_tenses = train_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "    vocab = train_class.vocab\n",
    "    print('Vocabulary size: %d' % len(vocab))\n",
    "\n",
    "    test_data_pth = os.path.join(data_pth, \"eval_data.csv\")\n",
    "    test_class = MonoTextData(test_data_pth, vocab=vocab, glove=True)\n",
    "    test_data, test_sentiments, test_tenses = test_class.create_data_batch_labels(args.bsz, device)\n",
    "\n",
    "    print(\"data done.\")\n",
    "\n",
    "    params = conf[\"params\"]\n",
    "    params[\"vae_params\"][\"vocab\"] = vocab\n",
    "    params[\"vae_params\"][\"device\"] = device\n",
    "\n",
    "    amolData = AmolData(test_data, test_sentiments, test_tenses, args.load_path, vocab, params[\"vae_params\"])\n",
    "    return amolData, train_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(data_name=\"yelp\", load_path = './checkpoint/ours-yelp/20201211-184811-first_run/', vocab = './tmp/yelp.vocab', bsz=256, embedding = './data/glove.840B.300d.txt', dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/yelp\n",
      "Vocabulary size: 9482\n",
      "data done.\n"
     ]
    }
   ],
   "source": [
    "obj, mtd = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_A0_df = pd.read_csv(\"data/yelp/eval_A0.csv\",sep=\"\\t\")\n",
    "eval_A1_df = pd.read_csv(\"data/yelp/eval_A1.csv\",sep=\"\\t\")\n",
    "eval_B0_df = pd.read_csv(\"data/yelp/eval_B0.csv\",sep=\"\\t\")\n",
    "eval_B1_df = pd.read_csv(\"data/yelp/eval_B1.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i in range(input_df.shape[0]):\n",
    "#     input_sentence = input_df['content'][i]\n",
    "#     processed_input = [mtd.vocab[w] for w in input_sentence.split()]\n",
    "#     processed_input = mtd._to_tensor([processed_input], False, 'cuda')\n",
    "#     output = obj.run_conversion(processed_input[0],1-sent,-1)\n",
    "#     input_df['generated_sent'][i] = \" \".join(output[0])\n",
    "\n",
    "# input_df['generated_sent'] = input_df['generated_sent'].str[3:-5]\n",
    "# input_df.to_csv(\"data/\"+model_name+\"_eval_A\"+str(sent)+\".csv\",sep=\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bleu = 0.0\n",
    "sources = []\n",
    "targets = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"M2\"\n",
    "sent = 1\n",
    "input_df = pd.read_csv(\"data/\"+model_name+\"_eval_A\"+str(sent)+\".csv\",sep=\"\\t\")\n",
    "target_df = pd.read_csv(\"data/yelp/eval_B\"+str(1-sent)+\".csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_df.shape[0]):\n",
    "    s = input_df['generated_sent'][i].split()\n",
    "    t = target_df['content'][i].split()\n",
    "    sources.append([s])\n",
    "    targets.append(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(499, 499)"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "len(sources), len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bleu: 13.81\n"
     ]
    }
   ],
   "source": [
    "total_bleu += compute_bleu(sources, targets)[0]\n",
    "total_bleu *= 100\n",
    "print(\"Bleu: %.2f\" % total_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}